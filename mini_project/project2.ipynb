{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import ObjectDetector\n",
    "\n",
    "model = ObjectDetector('ssd_mobilenet_v2_coco.engine')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Camera\n",
    "\n",
    "#camera = Camera.instance(width=224, height=224, fps=10)\n",
    "camera = Camera.instance(width=300, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'label': 62, 'confidence': 0.9489172101020813, 'bbox': [0.544226884841919, 0.42530083656311035, 0.7648848295211792, 0.8301563262939453]}, {'label': 62, 'confidence': 0.9107043743133545, 'bbox': [0.2586333751678467, 0.36154255270957947, 0.37204688787460327, 0.6386438608169556]}, {'label': 67, 'confidence': 0.7514657974243164, 'bbox': [0.008827745914459229, 0.7095703482627869, 0.8947507739067078, 0.9931215643882751]}, {'label': 73, 'confidence': 0.724090576171875, 'bbox': [0.6170546412467957, 0.3150652348995209, 0.6750434041023254, 0.37177708745002747]}, {'label': 1, 'confidence': 0.6136996746063232, 'bbox': [0.2146778404712677, 0.20606927573680878, 0.3894464075565338, 0.49528026580810547]}, {'label': 85, 'confidence': 0.5535053014755249, 'bbox': [0.7453811764717102, 0.08519567549228668, 0.7843281626701355, 0.15026691555976868]}, {'label': 1, 'confidence': 0.5380124449729919, 'bbox': [0.670075535774231, 0.22915251553058624, 0.7495537996292114, 0.37047845125198364]}, {'label': 67, 'confidence': 0.30404168367385864, 'bbox': [0.361159086227417, 0.30081433057785034, 0.7442538738250732, 0.6957611441612244]}]]\n"
     ]
    }
   ],
   "source": [
    "detections = model(camera.value)\n",
    "\n",
    "print(detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6688f8d0601482d9d02ef24be7ba587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value=\"[[{'label': 62, 'confidence': 0.9489172101020813, 'bbox': [0.544226884841919, 0.42530083656311…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "\n",
    "detections_widget = widgets.Textarea()\n",
    "detections_widget.value = str(detections)\n",
    "display(detections_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 62, 'confidence': 0.9489172101020813, 'bbox': [0.544226884841919, 0.42530083656311035, 0.7648848295211792, 0.8301563262939453]}\n"
     ]
    }
   ],
   "source": [
    "image_number = 0\n",
    "object_number = 0\n",
    "\n",
    "print(detections[image_number][object_number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "collision_model = torchvision.models.alexnet(pretrained=False)\n",
    "collision_model.classifier[6] = torch.nn.Linear(collision_model.classifier[6].in_features, 2)\n",
    "collision_model.load_state_dict(torch.load('best_model.pth'))\n",
    "device = torch.device('cuda')\n",
    "collision_model = collision_model.to(device)\n",
    "\n",
    "mean = 255.0 * np.array([0.485, 0.456, 0.406])\n",
    "stdev = 255.0 * np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "normalize = torchvision.transforms.Normalize(mean, stdev)\n",
    "\n",
    "def preprocess(camera_value):\n",
    "    global device, normalize\n",
    "    x = camera_value\n",
    "    # Image zoomed to 224,224 versus 224,244 obstacle avoidance model\n",
    "    x = cv2.resize(x, (224, 224))\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = normalize(x)\n",
    "    x = x.to(device)\n",
    "    x = x[None, ...]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot\n",
    "\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import PID\n",
    "\n",
    "#global follow_speed\n",
    "#follow_speed = 0.5\n",
    "#global turn_gain\n",
    "#turn_gain = 1.7\n",
    "#global follow_speed_pid, follow_speed_pid_model\n",
    "#follow_speed_pid_model = 1\n",
    "# follow_speed_pid = PID.PositionalPID(3, 0, 0)\n",
    "#follow_speed_pid = PID.PositionalPID(1.5, 0, 0.05)\n",
    "#global turn_gain_pid\n",
    "#turn_gain_pid = PID.PositionalPID(0.15, 0, 0.05)\n",
    "#global object_yservo_pid\n",
    "#object_yservo_pid = PID.PositionalPID(3, 0.5, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c81d7cbeaa59462eb8d457ee853c9153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Image(value=b'', format='jpeg', height='300', width='300'), FloatSlider(value=0.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-33b0391412be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0mimage_widget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbgr8_to_jpeg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m \u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'new'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-33b0391412be>\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(change)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'image_%d.jpeg'\u001b[0m\u001b[0;34m%\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbgr8_to_jpegto_jpeg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/posixpath.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mdiscarded\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mAn\u001b[0m \u001b[0mempty\u001b[0m \u001b[0mlast\u001b[0m \u001b[0mpart\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpath\u001b[0m \u001b[0mthat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     ends with a separator.\"\"\"\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_sep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "from jetbot import bgr8_to_jpeg\n",
    "\n",
    "blocked_widget = widgets.FloatSlider(min = 0.0,max=1.0,value=0.0,description='blocked')\n",
    "image_widget = widgets.Image(format='jpeg', width=300, height=300)\n",
    "label_widget = widgets.IntText(value=47, description='tracked label')\n",
    "speed_widget = widgets.FloatSlider(value=0.4,min=0.0,max=1.0,description='speed')\n",
    "turn_gain_widget = widgets.FloatSlider(value=0.8,min=0.0,max=2.0,description='turn gain')\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HBox([image_widget,blocked_widget]),\n",
    "    label_widget,\n",
    "    speed_widget,\n",
    "    turn_gain_widget\n",
    "]))\n",
    "\n",
    "width = int(image_widget.width)\n",
    "height = int(image_widget.height)\n",
    "\n",
    "def detection_center(detection):\n",
    "    \"\"\"Calculate the center x, y coordinates of the object\"\"\"\n",
    "    bbox = detection['bbox']\n",
    "    center_x = (bbox[0] + bbox[2]) / 2.0 - 0.5\n",
    "    center_y = (bbox[1] + bbox[3]) / 2.0 - 0.5\n",
    "    return (center_x, center_y)\n",
    "    \n",
    "def norm(vec):\n",
    "    \"\"\"Calculate the length of a two-dimensional vector\"\"\"\n",
    "    return np.sqrt(vec[0]**2 + vec[1]**2)\n",
    "\n",
    "def closest_detection(detections):\n",
    "    \"\"\"Find the detection closest to the center of the image\"\"\"\n",
    "    closest_detection = None\n",
    "    for det in detections:\n",
    "        center = detection_center(det)\n",
    "        if closest_detection is None:\n",
    "            closest_detection = det\n",
    "        elif norm(detection_center(det)) < norm(detection_center(closest_detection)):\n",
    "            closest_detection = det\n",
    "    return closest_detection\n",
    "        \n",
    "def execute(change):\n",
    "    global follow_speed\n",
    "    global turn_gain\n",
    "    global follow_speed_pid\n",
    "    target_value_speed = 0\n",
    "    #Update image value\n",
    "    #image = change['new']\n",
    "    #import os\n",
    "    #import time\n",
    "    #interval_seconds=5\n",
    "    #directory='image'\n",
    "    #count=0\n",
    "    #while True:\n",
    "     #   file_name = os.path.join(image,'image_%d.jpeg'% count)\n",
    "      #  with open(file_name,'wb') as f:\n",
    "       #     f.write(bgr8_to_jpegto_jpeg(camera.value))\n",
    "        count += 1\n",
    "        time.sleep(interval_seconds)\n",
    "\n",
    "    # Execute a conflict model to determine if it is blocking\n",
    "    # execute collision model to determine if blocked\n",
    "    # collision_output = collision_model(preprocess(image)).detach().cpu()\n",
    "    # Apply the \"softmax\" function to normalize the output vector to have a sum of 1 (this makes it a probability distribution)\n",
    "    # prob_blocked = float(F.softmax(collision_output.flatten(), dim=0)[0])\n",
    "    # blocked_widget.value = prob_blocked\n",
    "    \n",
    "    # Blocking does not execute the following object detection program, directly return to the next round of data refresh\n",
    "    # turn left if blocked\n",
    "    # if prob_blocked > 0.5:\n",
    "    #     robot.left(0.3)\n",
    "    #     image_widget.value = bgr8_to_jpeg(image)\n",
    "    #     return\n",
    "        \n",
    "    # compute all detected objects\n",
    "    detections = model(image)\n",
    "    # First, mark the non-tracking objects that appear with blue lines.\n",
    "    # Draw all detections on image\n",
    "    for det in detections[0]:\n",
    "        bbox = det['bbox']\n",
    "        cv2.rectangle(image, (int(300 * bbox[0]), int(300 * bbox[1])), (int(300 * bbox[2]), int(300 * bbox[3])), (255, 0, 0), 2)\n",
    "    # Select the object you want to track, select the value of label_widget,1 is person,\n",
    "    # select detections that match selected class label\n",
    "    matching_detections = [d for d in detections[0] if d['label'] == int(label_widget.value)]\n",
    "    \n",
    "    # Then mark the object to be tracked with green lines.\n",
    "    # get detection closest to center of field of view and draw it\n",
    "    det = closest_detection(matching_detections)\n",
    "    if det is not None:\n",
    "        bbox = det['bbox']\n",
    "        cv2.rectangle(image, (int(300 * bbox[0]), int(300 * bbox[1])), (int(300 * bbox[2]), int(300 * bbox[3])), (0, 255, 0), 4)\n",
    "\n",
    "    # otherwise go forward if no target detected\n",
    "    '''\n",
    "    blob:https---------A string of tags generated by the blob object in html5 after being assigned to the video tag.\n",
    "    '''\n",
    "    if det is None:\n",
    "        # robot.forward(float(follow_speed))\n",
    "        robot.stop()\n",
    "    # otherwsie steer towards target\n",
    "    else:\n",
    "        # move robot forward and steer proportional target's x-distance from center\n",
    "        center = detection_center(det)\n",
    "\n",
    "        #Follow speed PID adjustment\n",
    "        follow_speed_pid.SystemOutput = 90000 * (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])\n",
    "        if label_widget.value == 1:\n",
    "            follow_speed_pid.SetStepSignal(30000)\n",
    "        elif label_widget.value == 53 or label_widget.value == 55: # 53:Apple 55:orange\n",
    "            follow_speed_pid.SetStepSignal(10000)\n",
    "        else:\n",
    "            follow_speed_pid.SetStepSignal(10000)\n",
    "        follow_speed_pid.SetInertiaTime(0.2, 0.1)\n",
    "\n",
    "        #Steering gain PID adjustment\n",
    "        turn_gain_pid.SystemOutput = center[0]\n",
    "        turn_gain_pid.SetStepSignal(0)\n",
    "        turn_gain_pid.SetInertiaTime(0.2, 0.1)\n",
    "\n",
    "        #Limit steering gain to the effective range\n",
    "        if label_widget.value == 1:\n",
    "            target_value_turn_gain = 0.6 + abs(turn_gain_pid.SystemOutput)\n",
    "        elif label_widget.value == 53 or label_widget.value == 55:\n",
    "            target_value_turn_gain = 0.5 + abs(turn_gain_pid.SystemOutput)\n",
    "        else:\n",
    "            target_value_turn_gain = 0.5 + abs(turn_gain_pid.SystemOutput)\n",
    "        if target_value_turn_gain < 0:\n",
    "            target_value_turn_gain = 0\n",
    "        elif target_value_turn_gain > 2:\n",
    "            target_value_turn_gain = 2\n",
    "\n",
    "        #Keep the output motor speed within the effective driving range\n",
    "        target_value_speed = 0.46 + follow_speed_pid.SystemOutput / 90000\n",
    "        target_value_speedl = target_value_speed + target_value_turn_gain * center[0]\n",
    "        target_value_speedr = target_value_speed - target_value_turn_gain * center[0]\n",
    "        if target_value_speedl<0.5:\n",
    "            target_value_speedl=0\n",
    "        elif target_value_speedl>1:\n",
    "            target_value_speedl = 1\n",
    "        if target_value_speedr<0.5:\n",
    "            target_value_speedr=0\n",
    "        elif target_value_speedr>1:\n",
    "            target_value_speedr = 1\n",
    "\n",
    "        robot.set_motors(target_value_speedl, target_value_speedr)\n",
    "        \n",
    "        if label_widget.value != 1:\n",
    "            #Vertical angle camera PID adjustment\n",
    "            object_yservo_pid.SystemOutput =bbox[1]*300+150*(bbox[3] - bbox[1])\n",
    "            # print('Y-axis object center position value:')\n",
    "            # print(object_yservo_pid.SystemOutput)\n",
    "            object_yservo_pid.SetStepSignal(150)\n",
    "            object_yservo_pid.SetInertiaTime(0.2, 0.1)\n",
    "            #Limit the vertical angle camera angle to the specified range\n",
    "            target_value_object_yservo = int(2048 + object_yservo_pid.SystemOutput)\n",
    "            servo_device.Servo_serial_control(2, target_value_object_yservo)\n",
    "    # Update image display to widget\n",
    "    image_widget.value = bgr8_to_jpeg(image)\n",
    "    \n",
    "execute({'new': camera.value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#camera.unobserve_all()\n",
    "#camera.observe(execute, names='value')\n",
    "\n",
    "import threading\n",
    "import inspect\n",
    "import ctypes\n",
    "''' definition of the close thread function'''\n",
    "def _async_raise(tid, exctype):\n",
    "  \"\"\"raises the exception, performs cleanup if needed\"\"\"\n",
    "  tid = ctypes.c_long(tid)\n",
    "  if not inspect.isclass(exctype):\n",
    "    exctype = type(exctype)\n",
    "  res = ctypes.pythonapi.PyThreadState_SetAsyncExc(tid, ctypes.py_object(exctype))\n",
    "  if res == 0:\n",
    "    raise ValueError(\"invalid thread id\")\n",
    "  elif res != 1:\n",
    "    # \"\"\"if it returns a number greater than one, you're in trouble,\n",
    "    # and you should call it again with exc=NULL to revert the effect\"\"\"\n",
    "    ctypes.pythonapi.PyThreadState_SetAsyncExc(tid, None)\n",
    "    raise SystemError(\"PyThreadState_SetAsyncExc failed\")\n",
    "def stop_thread(thread):\n",
    "  _async_raise(thread.ident, SystemExit)\n",
    "'''The function of thread 1, which continuously calls the detection function'''\n",
    "def test():\n",
    "    while True:\n",
    "        execute({'new': camera.value})        \n",
    "\n",
    "thread1 = threading.Thread(target=test)\n",
    "thread1.setDaemon(False)\n",
    "thread1.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "stop_thread(thread1)\n",
    "camera.unobserve_all()\n",
    "time.sleep(1.0)\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
